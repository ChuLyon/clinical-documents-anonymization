{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f46b16-be4b-4602-a80d-a1df32ce81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Math utils\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForTokenClassification, get_scheduler\n",
    "from datasets import load_dataset, load_metric, Features, ClassLabel, Value, Sequence\n",
    "\n",
    "# Models used\n",
    "from transformers import CamembertTokenizerFast, CamembertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee9a3a-08e1-41a9-87e6-92caa51d5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup seeds to reproduce results\n",
    "SEED = 1312\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03475d18-aee6-42c5-aea3-1d1fa80c5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup default GPU to use\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.set_device(2)\n",
    "    print(\"cuDNN enabled? \", torch.backends.cudnn.enabled)\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "    print(\"cuda version:\", torch.version.cuda)\n",
    "    print(\"Device name? \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9f482-4023-4bac-95d0-7a7b72570c42",
   "metadata": {},
   "source": [
    "# Training french BERT models to detect tokens allowing to identifying patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675664b1-a5a6-4722-b0db-311532400fdd",
   "metadata": {},
   "source": [
    "The aim of this notebook is to train a BERT model, more especially a *CamemBERT* model, to detect terms in clinical document alowing to identify directly or indirectly a patient (names, ids, dates, etc.).\n",
    "\n",
    "This kind of task can be seen as Name Entity Recognition (NER) problem, also called token classification problem.\n",
    "\n",
    "First of all lets define the model we’ll use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4aec4a-bd7f-451c-a470-accc71434e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test with another model, change name and rerun all notebook\n",
    "model_name_prefix = \"camembert-base\"\n",
    "model_name_suffix = \"\" #\"-pretrained\"\n",
    "model_name = model_name_prefix + model_name_suffix\n",
    "dir_model = \"models\"\n",
    "if model_name_suffix != \"\":\n",
    "    dir_model += \"/saved_models/\" + model_name + \"/best\"\n",
    "else:\n",
    "    dir_model += \"/\"+model_name\n",
    "print(dir_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d116e-6c9b-4d77-8271-691eddda25ca",
   "metadata": {},
   "source": [
    "## Preparing datasets and dataloaders for Token Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836afd1-fb28-4771-b92a-daf74e056ef8",
   "metadata": {},
   "source": [
    "To train a model for token classification we need two things:\n",
    "\n",
    "1. defining classes to use to classify tokens\n",
    "2. loading a dataset of text with tokens already classified\n",
    "\n",
    "In our case we have 12 classes we aim to recognize by using a neural network, each class representing a piece of information that could conduct to the identification of a patient:\n",
    "\n",
    "* Postal Code (or Code postal in french), the code allowing to identify a town/city and then the location of a patient\n",
    "* City (or Ville in french), the name of a town/city allowing to identify the location of a patient\n",
    "* Street (or Voie in french), the street part of an adress allowing to identify the location of a patient\n",
    "* Locality (or Localité in french), the name of a country/region/state/department allowing to identify the location of a patient\n",
    "* FirstName/LastName (or Nom/Prénom in french), the first name and/or the last name of a person, allowing to identify a patient or a person linked to the patient (ex. a doctor)\n",
    "* Permanent Patient Identificator (or Identifiant Patient Permanent), an id allowing to identify directly a patient such as Social Security Number (or Numéro de Sécurité Sociale in french).\n",
    "* File Number (or Numéro de Dossier in french), the id of a medical file in the hospital, allowing to identify indirectly a patient\n",
    "* Phone Number (or Numéro de Téléphone in french), the phone number of a person (a patient or a person linked to the patient), allowing to identify at least the location of a patient\n",
    "* E-Mail, allowing to identify the name of a person (a patient or a person linked to the patient)\n",
    "* Organisation, the name of an organisation linked to treatement of a patient, allowing to identify indirectly a patient\n",
    "* Website (or site web in french), the url address of the website of a person or an organisation, allowing to identify this person or organisation and then inderectly a patient\n",
    "* Date, a date linked to healthcare process of a patient\n",
    "\n",
    "Because several successive words can be labelised under the same class, in token classification a distinction is made between the token starting a labelisation (noted *B-ClassName*) and tokens classified under a label already started (noted *I-ClassName*).\n",
    "\n",
    "In addition, we use the *O* class to identify tokens with no class.\n",
    "\n",
    "This give us 25 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca96b9-77b3-45ec-be76-cd28376de75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"O\", \"B-CodePostal\", \"I-CodePostal\", \"B-Ville\", \"I-Ville\", \"B-NomPrenom\", \"I-NomPrenom\", \"B-Voie\", \"I-Voie\", \"B-IPP\", \"I-IPP\", \"B-Date\", \"I-Date\", \"B-NoDossier\", \"I-NoDossier\", \"B-Organisation\", \"I-Organisation\", \"B-SiteWeb\", \"I-SiteWeb\", \"B-EMail\", \"I-EMail\", \"B-Localite\", \"I-Localite\", \"B-Telephone\", \"I-Telephone\"]\n",
    "features = Features({'id': Value(dtype='int64'), 'tokens': Sequence(feature=Value(dtype='string')), 'ner_tags': Sequence(feature=ClassLabel(names=label_names))})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd86c5-6ebf-458c-8f32-65b8f2f6c1c4",
   "metadata": {},
   "source": [
    "### Loading train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b6b950-8e0d-451c-8a9d-510091c0ca7e",
   "metadata": {},
   "source": [
    "To train our model on the identification 1240 medical have been labelised by 10 different peoples, with double-reading, according to the guidelines detailled in [LabelGuidelines.md](LabelGuidelines.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09af91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_file = 'data/anonymisation-ner.jsonl'\n",
    "\n",
    "cpt_labels = {}\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    json_list = list(f)\n",
    "    for json_str in tqdm(json_list):\n",
    "        result = json.loads(json_str)\n",
    "        for result_label in result[\"ner_tags\"]:\n",
    "            label_name = label_names[result_label]\n",
    "            if label_name not in cpt_labels:\n",
    "                cpt_labels[label_name] = 0\n",
    "            cpt_labels[label_name] += 1\n",
    "cpt_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccff543",
   "metadata": {},
   "source": [
    "With the aim to validate the feasability of our token classification problem by using a BERT model we’ll use cross-validation.\n",
    "\n",
    "To do so, we’ll load our labelised documents in 10 different training dataset each corresponding 90% of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a26e3-f36f-4166-914c-8ad54b298a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_datasets = load_dataset(\n",
    "    'json',\n",
    "    data_files=data_file,\n",
    "    features=features,\n",
    "    download_mode='force_redownload',\n",
    "    split=[f'train[:{k}%]+train[{k+10}%:]' for k in range(0, 100, 10)]\n",
    ")\n",
    "print(raw_train_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e16857-cb4e-42a9-930a-000a7898ae3e",
   "metadata": {},
   "source": [
    "And we load the 10% left of each training dataset into 10 validation datasets.\n",
    "\n",
    "Therefore, for each training dataset we’ll perform a clear training and validate the model on the corresponding validation dataset.\n",
    "\n",
    "This will give us more relevant result, avoiding cases where a model show very good results only for a specific "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085cdfb-7ba9-40cb-a666-68329f2f70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_datasets = load_dataset(\n",
    "    'json',\n",
    "    data_files=data_file,\n",
    "    features=features,\n",
    "    split=[f'train[{k}%:{k+10}%]' for k in range(0, 100, 10)]\n",
    ")\n",
    "print(raw_val_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f48ad-8d52-4168-9867-ec4a8c56ad81",
   "metadata": {},
   "source": [
    "## Preprocessing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c1882-34c1-485f-b235-7ae26d6bdadb",
   "metadata": {},
   "source": [
    "Before starting the training of our model, we need to preprocess our datasets to:\n",
    "\n",
    "- Have texts with a size treatable by our model\n",
    "- Align labels and tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f067a6-0b99-4827-836d-f8497a13baba",
   "metadata": {},
   "source": [
    "### Chunk texts of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b49a46-262f-4f75-b535-603ecf0a15cc",
   "metadata": {},
   "source": [
    "One problem with NLP models is that they have a limitation in size of text they can treat.\n",
    "\n",
    "In our case, CamemBERT models can treat texts with less that 512 tokens.\n",
    "\n",
    "Different methods can be used to overcome this limitation. For example, we can simply use the 512 first tokens of each texts.\n",
    "\n",
    "Because the documents we use can contain relevant information in all their contents, we choose to chunk our documents in subtexts of maximum 256 words.\n",
    "\n",
    "256 words because tokenizer generally split words in prefixes and suffixes. So, 256 words easily give 512 tokens.\n",
    "\n",
    "Fortunately, our datasets are already splitted into tokens with labels associated to each token.\n",
    "\n",
    "To chunk datasets, we first define the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b729c23-a4ff-4d63-92f0-e6ed85171293",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "subtext_size = int(embedding_dim / 2)\n",
    "stride = int(subtext_size / 2)\n",
    "\n",
    "\n",
    "def chunk_example(example):\n",
    "    tokens = example[\"tokens\"][0]\n",
    "    labels = example[\"ner_tags\"][0]\n",
    "    if len(tokens) <= subtext_size:\n",
    "        return {'tokens': [tokens], 'ner_tags': [labels]}\n",
    "\n",
    "    chunk_tokens = []\n",
    "    chunk_labels = []\n",
    "    for i in range(stride, len(tokens), stride):\n",
    "        sub_seq = [word for word in tokens[i-stride:i+stride]]\n",
    "        sub_labels = [label for label in labels[i-stride:i+stride]]\n",
    "        if len(sub_seq) != 0: #and any(label != 0 for label in sub_labels):\n",
    "            chunk_tokens.append(sub_seq)\n",
    "            chunk_labels.append(sub_labels)\n",
    "    return {'tokens': chunk_tokens, 'ner_tags': chunk_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8437f-5f8e-487a-af18-3193c0f4fb03",
   "metadata": {},
   "source": [
    "Then we apply this function to each of text of each training dataset using the *map* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57886081-876a-47e0-9f1d-412008ce4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_train_datasets = []\n",
    "for raw_dataset in raw_train_datasets:\n",
    "    chunked_train_datasets.append(raw_dataset.map(chunk_example, batched=True, batch_size=1, remove_columns=raw_dataset.column_names, load_from_cache_file=False))\n",
    "print(chunked_train_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14496ff4-6ab9-4a30-a02b-63cab7300915",
   "metadata": {},
   "source": [
    "We obtain then datasets with a mean size of 3838 texts by dataset.\n",
    "\n",
    "And we apply the methods on validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9786a7-bfd2-4707-a2f2-8cf4071a67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_val_datasets = []\n",
    "for raw_dataset in raw_val_datasets:\n",
    "    chunked_val_datasets.append(raw_dataset.map(chunk_example, batched=True, batch_size=1, remove_columns=raw_dataset.column_names, load_from_cache_file=False))\n",
    "print(chunked_val_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b95cbef-950c-4ffc-a47f-142588da7a7c",
   "metadata": {},
   "source": [
    "We obtain validation datasets with a mean size of 429 texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad39b3f-6be2-46a7-b590-9dc821b5aacc",
   "metadata": {},
   "source": [
    "### Align labels with tokenized texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fae03-a34c-4df0-b03e-7097c4fb9f17",
   "metadata": {},
   "source": [
    "The second step for preprocessing our datasets consist to align labels with how words will be tokenized by the model.\n",
    "\n",
    "For example, a text like:\n",
    "\n",
    "```\n",
    "Anne Honyme, habitant à Paris, consultation du 08/07/2022 aux HCL. \n",
    "```\n",
    "\n",
    "Will appeared in our dataset as following:\n",
    "\n",
    "```\n",
    "tokens: [\"Anne\", \"Honyme\", \",\", \"habitant\", \"à\", \"Paris\", \",\", \"consultation\", \"du\", \"08\", \"/\", \"07\", \"/\", \"2022\", \"aux\", \"HCL\" ]\n",
    "\n",
    "labels: [\"B-NomPrenom\", \"I-NomPrenom\", \"O\", \"O\", \"O\", \"B-Ville\", \"O\", \"O\", \"O\", \"B-Date\", \"I-Date\", \"I-Date\", \"I-Date\", \"I-Date\", \"O\", \"B-Organisation\"]\n",
    "\n",
    "label_ids = [5, 6, 0, 0, 0, 3, 0, 0, 0, 11, 12, 12, 12, 12, 0, 15]\n",
    "```\n",
    "\n",
    "But if we tokenize this text with the tokenizer of our model we obtain the following tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f01f3e-b62b-452e-85ab-de10bdc07f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizerFast.from_pretrained(\n",
    "        dir_model,\n",
    "        local_files_only=True\n",
    "    )\n",
    "\n",
    "example_tokens = tokenizer.tokenize([\"Anne\", \"Honyme\", \",\", \"habitant\", \"à\", \"Paris\", \",\", \"consultation\", \"du\", \"08\", \"/\", \"07\", \"/\", \"2022\", \"aux\", \"HCL\" ], is_split_into_words=True)\n",
    "print(example_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5071d6-3b18-488b-b7cf-97d20634f3a0",
   "metadata": {},
   "source": [
    "We can see that the tokenizer creates more tokens than the initial text.\n",
    "\n",
    "In consequence we need to align the labels set to the original text to the corresponding tokens in the tokenized text.\n",
    "\n",
    "To do so we define the following function that will, for each token get the corresponding word and associated label, then return a set of labels aligned with the new tokenized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b03fd-486b-421f-bbf4-2b93d783676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c906927e-d47a-4058-b984-715d82e0e7d4",
   "metadata": {},
   "source": [
    "If we get back our example we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6a03a-61d6-4d90-8dfb-7e193bede47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tokens = tokenizer([\"Anne\", \"Honyme\", \",\", \"habitant\", \"à\", \"Paris\", \",\", \"consultation\", \"du\", \"08\", \"/\", \"07\", \"/\", \"2022\", \"aux\", \"HCL\" ], is_split_into_words=True)\n",
    "example_labels = [5, 6, 0, 0, 0, 3, 0, 0, 0, 11, 12, 12, 12, 12, 0, 15]\n",
    "example_wordids = example_tokens.word_ids(0)\n",
    "print(example_wordids)\n",
    "print(align_labels_with_tokens(example_labels, example_wordids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967d49d-7f05-4482-ac9d-7c33efeee757",
   "metadata": {},
   "source": [
    "We now define a function to apply this function to a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42040ea-2aa0-4089-b091-644b7ecc361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(documents):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        documents[\"tokens\"], truncation=True, is_split_into_words=True, max_length=embedding_dim\n",
    "    )\n",
    "    all_labels = documents[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14b756-6f0a-479c-866d-ed8fb483ba20",
   "metadata": {},
   "source": [
    "Then we can apply this function to our training dataset using *map* fuction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ac33b-eb6a-4d2e-9f27-a41ec21b2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_datasets = []\n",
    "for chunked_dataset in chunked_train_datasets:\n",
    "    tokenized_train_datasets.append(chunked_dataset.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=chunked_dataset.column_names,\n",
    "        load_from_cache_file=False\n",
    "    ))\n",
    "\n",
    "print(tokenized_train_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46472aac-efe0-48b9-9eff-5b3debed84d5",
   "metadata": {},
   "source": [
    "And to our validation dataset using the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf458a-4700-4adc-9bc4-9c62b41590bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_val_datasets = []\n",
    "for chunked_dataset in chunked_val_datasets:\n",
    "    tokenized_val_datasets.append(chunked_dataset.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=chunked_dataset.column_names,\n",
    "        load_from_cache_file=False\n",
    "    ))\n",
    "\n",
    "print(tokenized_val_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73da99d-a092-4345-a766-462a255ba5ba",
   "metadata": {},
   "source": [
    "### Creation of DataLoader for Token Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af21ee-c090-40e0-960d-967d272929bb",
   "metadata": {},
   "source": [
    "Now that we have prepared our datasets, we still need to define the DataLoader that will generate the batches to train our model.\n",
    "\n",
    "To do so, we’ll need to define a Data Collator based on our tokenizer and the size of batches for our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c58636-aa67-4e50-8188-c836aa640b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d572b0c-a773-4346-bb97-936a2a697391",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d51aad8-3424-41c7-b40d-cc23304579b4",
   "metadata": {},
   "source": [
    "Then, because we’ll train and retrain our model on each training dataset, we define the following function to generate a training dataloader and a validation dataloader for each training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e3e8d-08d8-48f9-b518-4f556b6e3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset):\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        val_dataset, collate_fn=data_collator, batch_size=batch_size\n",
    "    )\n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16266b25-afa5-41cd-987a-b8a4b47f6741",
   "metadata": {},
   "source": [
    "## Fine-tuning the model for Token Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5be8c-0fce-4074-ba40-dfcc24cae432",
   "metadata": {},
   "source": [
    "Now that we have prepare our datasets and dataloaders, we can setup and train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c1f24-3576-43ab-aedf-ad4c2fc5e2de",
   "metadata": {},
   "source": [
    "### Define Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5eca19-e742-4bd5-b6db-b491c4c9d5a6",
   "metadata": {},
   "source": [
    "First, let us define where and how the fine-tuned models will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d271eab-4259-4bb0-8a76-f0cc7f10df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output_model = \"models/saved_models/\"+model_name+\"-finetuned\"\n",
    "\n",
    "def save_model(model, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    model_to_save.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c18110-881d-4229-80cb-4bab5263f508",
   "metadata": {},
   "source": [
    "### Define evaluation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8b1a5-ff1b-4636-ae16-071e4ecc1704",
   "metadata": {},
   "source": [
    "To evaluated the performances of the token classification we’ll need to use *seqeval* to compute all true/false positive/negative, and then recall, precision and F-1 scores of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8dceab-5006-4446-9f83-15b3aaec5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"my_seqeval.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd126f8a-3b74-47b4-96cf-9a5d863e546b",
   "metadata": {},
   "source": [
    "Then, we can define a function that, for a given model and validation dataloader, will return the performances of this model on this validation dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661df14-502c-420e-96bc-442d934ddd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_dataloader):\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            b_input_ids = batch['input_ids'].to(device)\n",
    "            outputs = model(b_input_ids)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        predictions = predictions.detach().cpu().clone().numpy()\n",
    "        labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "        # Remove ignored index (special tokens) and convert to labels\n",
    "        true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "        true_predictions = [\n",
    "            [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8aee4-1eb6-4976-b939-ac3cdfb155c5",
   "metadata": {},
   "source": [
    "We also define the following function to save the results obtained in a given directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952637e-28ab-4b23-979b-36adb0047acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid encoding errors\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def save_model_evaluation(results, dir_output):\n",
    "    output = dir_output+\"/eval-finetuning.csv\"\n",
    "    if not os.path.exists(output):\n",
    "        f = open(output, \"w\", encoding=\"utf-8\")\n",
    "        f.write(\"model;pretrained\")\n",
    "        # write heads\n",
    "        for key in results:\n",
    "            if type(results[key]) is dict :\n",
    "                for key2 in results[key]:\n",
    "                    f.write(\";\"+key+\"-\"+key2)\n",
    "            else:\n",
    "                f.write(\";\"+key)\n",
    "        f.write(\"\\n\")\n",
    "    else:\n",
    "        f = open(output, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "    f.write(model_name_prefix+\";\"+str(model_name_suffix != \"\"))\n",
    "    for key in results:\n",
    "        if type(results[key]) is dict :\n",
    "            for key2 in results[key]:\n",
    "                f.write(\";\"+str(round(results[key][key2], 5)))\n",
    "        else:\n",
    "            f.write(\";\"+str(round(results[key], 5)))\n",
    "    f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78f539-cb5f-4636-8012-409016d0cd02",
   "metadata": {},
   "source": [
    "### Prepare models to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426f0fd-fb12-4b7f-bb48-232e7506dfe5",
   "metadata": {},
   "source": [
    "To prepare our model, we first need to indicate it how to get a label from its id, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05152a-1ab2-423c-98ec-c887ebeace44",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df8141-9737-4103-b721-2aaeabab9872",
   "metadata": {},
   "source": [
    "Then, because we want to train our model for each dataset, we define the following function that will create and return a clean version of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7707b-bb58-4e21-a5b0-6b7e60e183fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(dir_model):\n",
    "    model = CamembertForTokenClassification.from_pretrained(\n",
    "            dir_model,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            local_files_only=True\n",
    "        )\n",
    "\n",
    "    model.to(device);\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288517f-e0c9-4858-88e1-a90a09ceb529",
   "metadata": {},
   "source": [
    "### Setup training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a815c-4d6b-4571-bb1a-6a76c6c0e332",
   "metadata": {},
   "source": [
    "Last step before launch the training loop, we have to define the optimizers and the scheduler for our training.\n",
    "\n",
    "First, let us define the hyperparameters for our optimizer (learning rate and adam epsilon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af192686-f51a-42dd-9616-3d0f99a7e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 1e-4\n",
    "adam_epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc622d03-0746-44dc-b065-35e67147e6a2",
   "metadata": {},
   "source": [
    "Then, we define the following function to create an optimizer for given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c9a1b-0393-4ded-962a-3ae469aeff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_optimizer(model):\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        eps=adam_epsilon\n",
    "    )\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62731f-00c9-4c19-848d-0b891443014f",
   "metadata": {},
   "source": [
    "Now, we have to define the number of epochs for our training, in other words the number of time our model we’ll see the totality of the training dataset during its training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c5810-19b0-40fc-b25c-f660f2cb3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9df542-5b05-491c-933e-278fc5899b9c",
   "metadata": {},
   "source": [
    "Then, we define the following function to generate a scheduler for a given optimizer and training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8f0dd-60e7-4c79-ae37-7e4ff232ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_scheduler(optimizer, train_dataloader):\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "    scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86657412-5f48-44c5-8f8c-3d194d17cbd3",
   "metadata": {},
   "source": [
    "### Launch training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86cec10-630b-40e0-9f1d-5ee128235ecb",
   "metadata": {},
   "source": [
    "Finally, we can start the training of our model.\n",
    "\n",
    "For each training dataset, and its corresponding validation dataset, we create a training and a validation dataloaders.\n",
    "\n",
    "Then, we create a new model with new optimzer and scheduler.\n",
    "\n",
    "Once the training done, we evaluate the model on the validation dataset and save its results. And if its overall f1-score is better than previous models, we save this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45040d78-2756-42ca-b304-d7389ef8e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(dir_output_model):\n",
    "    shutil.rmtree(dir_output_model)\n",
    "\n",
    "best_fscore = 0.0\n",
    "\n",
    "for i in tqdm(range(4), desc=\"cross-validation\"):\n",
    "\n",
    "    train_dataloader, eval_dataloader = create_dataloaders(tokenized_train_datasets[i], tokenized_val_datasets[i])\n",
    "\n",
    "    model = prepare_model(dir_model)\n",
    "    optimizer = prepare_optimizer(model)\n",
    "    scheduler = prepare_scheduler(optimizer, train_dataloader)\n",
    "\n",
    "    barepochs = tqdm(range(num_epochs))\n",
    "    for j in barepochs:\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"batches\")):\n",
    "            b_input_ids = batch['input_ids'].to(device)\n",
    "            b_input_label = batch['labels'].to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(b_input_ids, labels=b_input_label)\n",
    "\n",
    "            loss = outputs[0]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        barepochs.set_description(\n",
    "            desc=\"loss: \"+str(round(avg_train_loss, 5))\n",
    "        )\n",
    "\n",
    "        save_model(model, dir_output_model+\"/last\")\n",
    "\n",
    "    results = evaluate_model(model, eval_dataloader)\n",
    "    if results[\"overall_f1\"] > best_fscore :\n",
    "        best_fscore = results[\"overall_f1\"]\n",
    "        save_model(model, dir_output_model+\"/best\")\n",
    "\n",
    "    save_model_evaluation(results, dir_output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71c26b-8c2a-48c7-8890-c557c6c61930",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8604ea-80b8-44a3-b80a-571e80e63331",
   "metadata": {},
   "source": [
    "Lets load the file where results of cross validation have been written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87fdf9-a23a-40b2-b3ae-58ec1b52efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_results = pd.read_csv(dir_output_model+\"/eval-finetuning.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dac984-9b39-419a-b82d-ec14b4dfc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6a276-dcfc-4798-92da-55931dfa97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"label\\t\\tprecision\\t\\trecall\\t\\tf1-score\")\n",
    "for label in [\"CodePostal\", \"Ville\", \"NomPrenom\", \"Voie\", \"IPP\", \"Date\", \"NoDossier\", \"Organisation\", \"SiteWeb\", \"EMail\", \"Localite\", \"Telephone\"]:\n",
    "    print(label, end=\"\")\n",
    "    for score in [\"precision\", \"recall\", \"f1\"]:\n",
    "        key = label+\"-\"+score\n",
    "        if key in cross_results:\n",
    "            print(\n",
    "                    \"\\t\\t\"+\n",
    "                    str(round(statistics.mean(cross_results[key]), 3))+\n",
    "                    \" ± \"+\n",
    "                    str(round(statistics.stdev(cross_results[key]), 3)),\n",
    "                    end=\"\"\n",
    "                 )\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Math utils\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "# ML utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DataCollatorForLanguageModeling, get_linear_schedule_with_warmup\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "# Models used\n",
    "from transformers import pipeline, CamembertTokenizerFast, CamembertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14910a-f6e6-413f-8751-7aec0e19c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup seeds to reproduce results\n",
    "SEED = 1312\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa87ba-1c8d-4760-bbe7-d0fd9aeb9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CPU/GPU to use\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.set_device(2)\n",
    "    print(\"cuDNN enabled? \", torch.backends.cudnn.enabled)\n",
    "    print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "    print(\"cuda version:\", torch.version.cuda)\n",
    "    print(\"Device name? \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06571c50",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pretraining french BERT models on french clinical documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce4c4c-7df5-4ab2-be2f-71c67494d67f",
   "metadata": {},
   "source": [
    "A first limitation of BERT models to treat documents from a specific domain, here healthcare, is their absence of knowledge on the vocabulary used in this domain.\n",
    "\n",
    "In our case, we aim to use CamemBERT models on french clinical documents. CamemBERT being trained on french general documents, it have a good knowledge of french language, but not on  french clinical language (as we’ll see later in this document).\n",
    "\n",
    "Therefore, to potentially improve the detection of identifying data on documents, we first want to pretrain CamemBERT models on a large panel of various clinical documents.\n",
    "\n",
    "First, lets define the model we’ll use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65182112-500a-4da4-98e3-fd5153b4e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test with another model, change name and rerun the all notebook\n",
    "model_name = \"camembert-base\"\n",
    "dir_model = \"models/\" + model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0d84f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing datasets and dataloaders for Masked Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7718e-ad2a-42e0-ba6d-ed65ebba2548",
   "metadata": {},
   "source": [
    "To teach a new language to a model, we generally train it on a Fill-Mask problem.\n",
    "\n",
    "Fill-Mask problems simply refers to a texts with missing words that the model have to find.\n",
    "\n",
    "To do so, we transform the texts from our datasets and \"mask\" randomly some words, more specificaly \"tokens\".\n",
    "\n",
    "We’ll use the following text, from the validation dataset, to explain the process in the sections below:\n",
    "\n",
    "```\n",
    "Contrôle 1 an 1/2 après cystoprostatectomie radicale avec Bricker Va bien , asymptomatique Pas d'infection urinaire symptomatique La stomie est jolie L'appareillage se fait sans difficulté La créatinine est normale = 7,7 Le scanner thoraco-abdomino-pelvienne est normal et supperposable aux scanners précédents Les reins ne sont pas dilatés.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edda55-8bde-4464-af90-4ff28590e4a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afecb6-3940-4564-8430-619e0615c8c2",
   "metadata": {},
   "source": [
    "To build datasets for pretraining, we have extracted close to one milion heterogenous clinical documents. However, some this file had encoding errors (special symbols, unreadable documents, missing letters, etc.).\n",
    "\n",
    "After cleaning, we obtained 613650 documents (~1.4Gb).\n",
    "\n",
    "Then, we use the bootstraping method to create a dataset for training and a dataset for test and validation.\n",
    "\n",
    "The code used to bootstrap the raw dataset can be found in [Bootstrapping.ipynb](Boostrapping.ipynb).\n",
    "\n",
    "So, lets load raw texts from the training and validation datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972646fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trainingset = []\n",
    "with open(\"data/data-for-trf-train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(\"loading json...\")\n",
    "    jsonfile = json.load(f)\n",
    "    print(\"json loaded\")\n",
    "    raw_trainingset = [datum[\"file.contenu\"] for datum in tqdm(jsonfile)]\n",
    "print(len(raw_trainingset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_validset = []\n",
    "with open(\"data/data-for-trf-validation.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(\"loading json...\")\n",
    "    jsonfile = json.load(f)\n",
    "    print(\"json loaded\")\n",
    "    raw_validset = [datum[\"file.contenu\"] for datum in tqdm(jsonfile)]\n",
    "print(len(raw_validset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953abcaf-62aa-422e-93bb-865adea47511",
   "metadata": {},
   "source": [
    "We obtain a training dataset and a validation dataset with repectively: 613650 texts, same as the raw dataset but with duplications due to bootstraping, and 225794 texts. Both datasets are totally disjoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c87845-d39f-435d-b235-7471e9f29577",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6b5fe-d683-413e-a0e7-6f5a0442734c",
   "metadata": {},
   "source": [
    "One problem with NLP models is that they have a limitation in size of text they can treat.\n",
    "\n",
    "In our case, CamemBERT models can treat texts with less that 512 tokens.\n",
    "\n",
    "Different methods can be used to overcome this limitation. For example, we can simply use the 512 first tokens of each texts.\n",
    "\n",
    "Because the documents we use can contain relevant information in all their contents, we choose to chunk our documents in subtexts of maximum 256 words.\n",
    "\n",
    "256 words because, as we’ll see after, tokenizer generally split words in prefixes and suffixes. So, 256 words easily give 512 tokens.\n",
    "\n",
    "To split texts into words, we use the tokenizer *Whitespace* of **HugginFace**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778d44e-ec14-49ce-85e4-7ed53836a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ed236-3b4a-4b80-834f-a6697c8ab844",
   "metadata": {},
   "source": [
    "With our example we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00a09d-325d-472d-aa69-74a2271d4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tokenized_example = pre_tokenizer.pre_tokenize_str(\"Contrôle 1 an 1/2 après cystoprostatectomie radicale avec Bricker Va bien , asymptomatique Pas d'infection urinaire symptomatique La stomie est jolie L'appareillage se fait sans difficulté La créatinine est normale = 7,7 Le scanner thoraco-abdomino-pelvienne est normal et supperposable aux scanners précédents Les reins ne sont pas dilatés.\")\n",
    "print(\"Number of words:\", str(len(pre_tokenized_example)))\n",
    "print(pre_tokenized_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e594321-4ad1-4e3a-a40b-9a493e42483e",
   "metadata": {},
   "source": [
    "For texts with more than 256 words, the idea is to chunk texts using a stride of 128 words to obtain subtexts in a staggered arrangement.\n",
    "\n",
    "We define then the sizes we’ll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cad4d-1511-4c38-a063-dde2ce2af3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "subtext_size = int(embedding_dim / 2)\n",
    "stride = int(subtext_size / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634956f1-eb0d-4839-8334-067a9d730885",
   "metadata": {},
   "source": [
    "And we pretokenize texts of our two datasets and chunk them if necessary. (for demonstration we limit the number of texts to tokenize and chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfe01f-b970-4add-9d7a-1cf353b18229",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretokenized_trainingset = []\n",
    "for seq in tqdm(raw_trainingset[:1000]):\n",
    "    tokenized_seq = pre_tokenizer.pre_tokenize_str(seq)\n",
    "    if len(tokenized_seq) <= subtext_size:\n",
    "        pretokenized_trainingset.append(seq)\n",
    "    else:\n",
    "        for i in range(stride, len(tokenized_seq), stride):\n",
    "            sub_tokenized_seq = tokenized_seq[i-stride:i+stride]\n",
    "            sub_seq_start = sub_tokenized_seq[0][1][0]\n",
    "            sub_seq_end = sub_tokenized_seq[-1][1][1]\n",
    "            sub_seq = seq[sub_seq_start:sub_seq_end]\n",
    "            if len(sub_seq) != 0:\n",
    "                pretokenized_trainingset.append(sub_seq)\n",
    "print(len(pretokenized_trainingset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2dea6b-6c9c-4125-a35d-5efad0e51c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretokenized_validset = []\n",
    "for seq in tqdm(raw_validset[:100]):\n",
    "    tokenized_seq = pre_tokenizer.pre_tokenize_str(seq)\n",
    "    if len(tokenized_seq) <= subtext_size:\n",
    "        pretokenized_validset.append(seq)\n",
    "    else:\n",
    "        for i in range(stride, len(tokenized_seq), stride):\n",
    "            sub_tokenized_seq = tokenized_seq[i-stride:i+stride]\n",
    "            sub_seq_start = sub_tokenized_seq[0][1][0]\n",
    "            sub_seq_end = sub_tokenized_seq[-1][1][1]\n",
    "            sub_seq = seq[sub_seq_start:sub_seq_end]\n",
    "            if len(sub_seq) != 0:\n",
    "                pretokenized_validset.append(sub_seq)\n",
    "print(len(pretokenized_validset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899bd27-60a6-4b7c-b972-9709aeeaa322",
   "metadata": {},
   "source": [
    "We obtain then two augmented datasets for training and validation, already split into words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce8ef19-09cb-4781-81f8-9bec51845af4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Learn clinical vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d83fd-5019-4a69-b06c-ec68ccf405a7",
   "metadata": {},
   "source": [
    "To train our model on a new language, we first need to learn the vocabulary of this language by trainning the tokenizer of CamemBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340af78-e528-48b2-a25e-a4be9bc327ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokenizer = CamembertTokenizerFast.from_pretrained(\n",
    "        dir_model,\n",
    "        local_files_only=True\n",
    "    )\n",
    "\n",
    "print(old_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b076c-b275-4576-b29b-2467ad18ed00",
   "metadata": {},
   "source": [
    "With our example, the tokenizer of CamemBERT gives us the following result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c98580-9422-44a1-a988-1c8a90879233",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = old_tokenizer.tokenize(\"Contrôle 1 an 1/2 après cystoprostatectomie radicale avec Bricker Va bien , asymptomatique Pas d'infection urinaire symptomatique La stomie est jolie L'appareillage se fait sans difficulté La créatinine est normale = 7,7 Le scanner thoraco-abdomino-pelvienne est normal et supperposable aux scanners précédents Les reins ne sont pas dilatés.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48daf3a-1353-4665-9e91-885465c18822",
   "metadata": {},
   "source": [
    "We can see that terms specific to the clinical language such as \"cystoprostatectomie\", \"créatinine\" or \"thoraco-abdomino-pelvienne\" are tokenized into letters. Its because the tokenizer of camembert doesn’t know the vocabulary specific to clinical documents.\n",
    "\n",
    "To train the tokenizer of CamemBERT to learn a new vocabulary we’ll use the method *train_new_from_iterator* (available only for *Fast* tokenizers).\n",
    "\n",
    "First, we have to define a function to iterate documents from the trainning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16fc3e3-a7ab-43ab-bd5e-d6a1d90a8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        raw_trainingset[i : i + 1000]\n",
    "        for i in range(0, len(raw_trainingset), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bdb315-4de4-4e6a-90cd-f1a3299a63fb",
   "metadata": {},
   "source": [
    "Then, we can train the tokenizer of CamemBERT on texts from the trainning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b6904-1b91-4d39-9355-c9b3b0853e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, old_tokenizer.vocab_size)\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83072c-07fb-4112-9ea6-d36bf9293209",
   "metadata": {},
   "source": [
    "With our example, we obtain now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ae01d-18a4-4d10-94fe-31a80c96bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(\"Contrôle 1 an 1/2 après cystoprostatectomie radicale avec Bricker Va bien , asymptomatique Pas d'infection urinaire symptomatique La stomie est jolie L'appareillage se fait sans difficulté La créatinine est normale = 7,7 Le scanner thoraco-abdomino-pelvienne est normal et supperposable aux scanners précédents Les reins ne sont pas dilatés.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8ae8c-60f1-4260-a3cc-e2036877dcdd",
   "metadata": {},
   "source": [
    "We can observe that clinical terms like \"cystoprostatectomie\", \"créatinine\" or \"thoraco-abdomino-pelvienne\" are better tokenized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a098689",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create data loaders for fill-mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56727e46-434c-4853-b209-04397b80c713",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we need to create dataloaders that will generate texts with masked tokens and their corresponding tokens to find.\n",
    "\n",
    "First, we have to create a *Dataset* adapted to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be52a9c-2e3b-4899-95cc-e89a394f1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLMDataset(Dataset):\n",
    "    def __init__(self, text_lines, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lines = text_lines\n",
    "        self.max_len = max_len\n",
    "        self.ids = self.encode_lines(self.lines)\n",
    "\n",
    "    def encode_lines(self, lines):\n",
    "        batch_encoding = self.tokenizer(\n",
    "            lines,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len\n",
    "        )\n",
    "        return batch_encoding[\"input_ids\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.ids[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba45d7-4dcf-49b0-94bc-382d707fa6e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Then, we create a data collator that will tokenize our texts and determine which ones to mask.\n",
    "\n",
    "The probability for a token to be masked is set at 15\\%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4a42b-bb19-4fdb-8f17-2bd570879ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=True,\n",
    "        mlm_probability=0.15\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51515fc7-4b42-4d7c-8d32-56ddc30f787d",
   "metadata": {},
   "source": [
    "After that we can create a dataloader that generate batches of texts with masked tokens, based on the texts from our training dataset.\n",
    "\n",
    "The size of batches is set at 4 to avoid memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6790333-ddd8-4e2d-9e7b-144b133ee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a4e55-167c-440e-8593-546348106687",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MaskedLMDataset(\n",
    "        pretokenized_trainingset,\n",
    "        tokenizer,\n",
    "        embedding_dim\n",
    "    )\n",
    "\n",
    "training_dataloader = DataLoader(\n",
    "        training_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd9fe18-28d5-4a60-b88d-1e25e98a4e72",
   "metadata": {},
   "source": [
    "Then, we do the same on 1\\% of the validation dataset to create a dataloader to briefly test the model during its training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1cbbd-4687-4c00-9ebc-689e8632840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 per cent of the validation dataset is used to test model during training\n",
    "test_size = int(len(pretokenized_validset) * 0.01)\n",
    "random.shuffle(pretokenized_validset)\n",
    "\n",
    "test_dataset = MaskedLMDataset(\n",
    "        pretokenized_validset[:test_size],\n",
    "        tokenizer,\n",
    "        embedding_dim\n",
    "    )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4343fd-700a-4ff0-be4c-a3d98a68f72d",
   "metadata": {},
   "source": [
    "Finally, we create the dataloader for the rest of the validation dataset, that we’ll use to validate our models once its training will be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe2282-b749-41f0-b645-6152e56ce725",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = MaskedLMDataset(\n",
    "        pretokenized_validset[test_size:],\n",
    "        tokenizer,\n",
    "        embedding_dim\n",
    "    )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "        validation_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3636e523-00cc-47bc-b5e1-eb6fbec3b47b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Camembert for Masked Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80619edd-6d69-44ef-8c92-4285d7fd7936",
   "metadata": {},
   "source": [
    "Now that we have prepare our datasets, we can setup parameters for the training of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e311e14-78b1-446f-be7f-5bfd2ccd3a19",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d0644-2186-431c-b75e-2ddbf04e31d4",
   "metadata": {},
   "source": [
    "First, lets define where and how the model will be saved during and after its training.\n",
    "\n",
    "We can see that we save the new tokenizer in the same directory that our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9f690-67e3-4cd1-8b21-c0a8deca1bad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_name = \"models/saved_models/\"+model_name+\"-pretrained/\"\n",
    "\n",
    "\n",
    "def save_model(model, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    model_to_save.save_pretrained(save_dir)\n",
    "    tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4676d1c-aab0-41c1-997d-c04e29dd1646",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define evaluation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4860927-2956-4f1f-9461-fdf031489a12",
   "metadata": {},
   "source": [
    "Secondly, lets define how the function we will use to evaluate the model during and once its training will be done.\n",
    "\n",
    "This function compute the perplexity of a given model’s results for each batches of a given dataloader.\n",
    "\n",
    "Perplexity evaluates the probabilities assigned to a token proposed by the model for a masked token, knowing the other tokens before the masked one. Lower perplexity indicates better performance.\n",
    "\n",
    "Perplexity can be obtain from the loss of the model after a prediction.\n",
    "\n",
    "The function return the perplexities obtained for all batches, allowing us to make some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bfb9b-26d5-499f-9869-b51a882e3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"compute perplexity\"):\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_input_label = batch['labels'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, labels=b_input_label)\n",
    "            loss = outputs[0]\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18431d4b-4313-4727-8f04-a088dae55f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare CamemBERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33d0cb-5635-47e7-965f-6391d83060b8",
   "metadata": {},
   "source": [
    "Now, we can prepare the CamemBERT model for training.\n",
    "\n",
    "First, we loading it from local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b92b74-6f22-4487-b60b-e67f227fed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertForMaskedLM.from_pretrained(\n",
    "        dir_model,\n",
    "        local_files_only=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc54ef-b16c-419c-b565-ee932e302cc5",
   "metadata": {},
   "source": [
    "And then, we can load the model on the predefined GPU (or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ab9ef-f25f-4f6c-ae3a-9db1de9bf9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9987dd-fb8c-4ae9-8601-44e9d37d0dbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed420a-83ff-4f61-9411-aba4ce676f5d",
   "metadata": {},
   "source": [
    "Now that we have prepared our model, we can make our last settings before starting our training loop.\n",
    "\n",
    "First, we define the hyperparameters to use *AdamW* optimizer.\n",
    "\n",
    "A learning rate at 1.10⁻⁴ to start, and an epsilon at 1.10⁻⁸ to avoid dividing by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d14225-bd48-4728-89a7-753d18878687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 1e-4\n",
    "adam_epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b39f9c-0627-4fa3-90ad-78e56933a038",
   "metadata": {},
   "source": [
    "Then, we define the *AdamW* optimizer for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416efec0-480d-40f0-8fe4-8d854235d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        eps=adam_epsilon\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb629ae-aa8e-45a8-a34d-17dcddaa8c1d",
   "metadata": {},
   "source": [
    "After that, we only have to define the scheduling of our training loop.\n",
    "\n",
    "To do so, we first define the number of epoch we want to do and obtain the total number of steps of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4286b-017c-4ebe-8f66-81dbd739bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "total_steps = len(training_dataloader) * num_epochs\n",
    "print(total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1bc85-efaf-4941-a3f2-f6b62f38455f",
   "metadata": {},
   "source": [
    "Then, we can define our scheduler based on this total number of steps to adapt model’s parameters during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358bd22-5bc5-4ea2-a01c-6cd311095668",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a0cd3-e7be-4ae9-9d21-726b237586e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f367da8-e481-4305-bd90-48deabdea0e4",
   "metadata": {},
   "source": [
    "Now, we have everything we need to train our model.\n",
    "\n",
    "For each epoch, we train our model on the whole training dataset.\n",
    "\n",
    "At the end of each epoch, we compute the perplexity of our model on the test dataset.\n",
    "\n",
    "If the perplexity is better than before we save the model in *best* subdirectory.\n",
    "In all cases, we save the last version of the model in *last* subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73455b5f-2cb0-4b50-a684-07fdb0bfcfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_perplexity = sys.float_info.max\n",
    "barepochs = tqdm(range(num_epochs))\n",
    "for i in barepochs:\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(training_dataloader, desc=\"batches\")):\n",
    "        b_input_ids = batch['input_ids'].to(device)\n",
    "        b_input_label = batch['labels'].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, labels=b_input_label)\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(training_dataloader)\n",
    "\n",
    "    test_perplexity = statistics.mean(compute_perplexity(model, test_dataloader))\n",
    "    if test_perplexity < best_perplexity:\n",
    "        best_perplexity = test_perplexity\n",
    "        save_model(model, dir_name+\"best\")\n",
    "    save_model(model, dir_name+\"last\")\n",
    "\n",
    "    barepochs.set_description(\n",
    "        desc=\"loss: \"+str(round(avg_train_loss, 4))+\", test: \"+str(round(test_perplexity, 2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb97e89-6b76-4a4d-9ddf-3676585ddee0",
   "metadata": {},
   "source": [
    "## Evaluating and validating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e53aaa-8954-4dff-8aa2-d28feaeca6ee",
   "metadata": {},
   "source": [
    "Now that our training is done, lets evaluate the performances of pertrained model in comparison to the CamemBERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef94b3b-cb0f-4d42-9423-162f2fef14d8",
   "metadata": {},
   "source": [
    "### Evaluate perplexities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ed99f-af88-49b9-81b1-81a30c4795dd",
   "metadata": {},
   "source": [
    "First lets evaluate the average perplexity obtain by each model on our validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52216dc-b55a-4c9f-b5e2-cc1957920022",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        \"not-pretrained\": dir_model,\n",
    "        \"pretrained\": dir_name+\"best\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b333b4-dfb1-4fe8-a423-f95473292613",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models:\n",
    "    # load model\n",
    "    model = CamembertForMaskedLM.from_pretrained(\n",
    "                            models[key],\n",
    "                            local_files_only=True\n",
    "                        )\n",
    "\n",
    "    model.to(device);\n",
    "\n",
    "    perplexities = compute_perplexity(model, validation_dataloader)\n",
    "    print(\n",
    "        \"Average Perplexity for\", key, \":\",\n",
    "        str(statistics.mean(perplexities)),\n",
    "        \"±\",\n",
    "        str(statistics.stdev(perplexities))\n",
    "    )\n",
    "\n",
    "    # save results\n",
    "    with open(dir_name+key+\"_perplexity.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(perplexities, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478f9ff-46f0-4acf-a0d9-8e43827ce0b6",
   "metadata": {},
   "source": [
    "### Example of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec12efa-d967-46a7-88f2-4b8eb8fb22e6",
   "metadata": {},
   "source": [
    "Finally, lets compare our models on some example from our validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe1b51-0eda-4664-a24c-a1dff47f4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = {\n",
    "    \"Contrôle 1 an 1/2 après cystoprostatectomie radicale avec Bricker.\":\n",
    "    \"Contrôle 1 an 1/2 après <mask> radicale avec Bricker.\",\n",
    "    \"A ce stade, il existe des ondes lentes diphasiques dans les deux régions frontales intermittentes.\":\n",
    "    \"A ce stade, il existe des ondes lentes <mask> dans les deux régions frontales intermittentes.\",\n",
    "    \"Ordonnance bi-zone Prescriptions relatives au traitement de l'affection de longue durée.\":\n",
    "    \"Ordonnance bi-zone <mask> relatives au traitement de l'affection de longue durée.\",\n",
    "    \"Le contrôle de la fistule huméro-basilique gauche est plutôt bon puisque la fistule est hyper-débitante, environ 2L avec des IR à 0.53 sans sténose significative retrouvée.\":\n",
    "    \"Le contrôle de la <mask> huméro-basilique gauche est plutôt bon puisque la fistule est hyper-débitante, environ 2L avec des IR à 0.53 sans sténose significative retrouvée.\",\n",
    "    \"Dévitaion du dorsum nasal obcjctivée et subjective, vers la gauche avec enfoncement des OPN droits gène à la ventilation nasale rappportée spontanément par le patient\":\n",
    "    \"Dévitaion du dorsum <mask> obcjctivée et subjective, vers la gauche avec enfoncement des OPN droits gène à la ventilation nasale rappportée spontanément par le patient\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243f6bf-a9d2-4a17-bf3c-7f32857c3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"not-pretrained\": pipeline(\"fill-mask\", dir_model),\n",
    "    \"pretrained\": pipeline(\"fill-mask\", dir_name+\"best\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e921fa-fbfd-49ed-a5df-a1133dfc2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in example_dataset:\n",
    "    print(text)\n",
    "    print(example_dataset[text])\n",
    "\n",
    "    for classifier_name in classifiers:\n",
    "        print(classifier_name+\":\")\n",
    "        results = classifiers[classifier_name](example_dataset[text])\n",
    "\n",
    "        for result in results:\n",
    "            print(result[\"token_str\"]+\" (\"+str(round(result[\"score\"], 2))+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb95e39-4cb2-4ce4-b2d7-dbade5451bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
